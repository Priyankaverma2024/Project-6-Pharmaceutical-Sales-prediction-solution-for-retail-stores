{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMgPjc08t7pULh4YE6GUSSu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Priyankaverma2024/Project-6-Pharmaceutical-Sales-prediction-solution-for-retail-stores/blob/main/Copy_of_Logger.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "l79pCP4_e5SW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4QYNKt7sifnL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "w59I-UUlbQnM"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import joblib\n",
        "# create logger\n",
        "import logging\n",
        "import sys"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Configure Logger\n",
        "def setup_logger(log_file='Sales_prediction_Model.log'):\n",
        "    # Create a logger\n",
        "    logger = logging.getLogger('SalesPredictionLogger')\n",
        "    logger.setLevel(logging.DEBUG)\n",
        "\n",
        "    # Create file handler to save logs to a file\n",
        "    file_handler = logging.FileHandler(log_file)\n",
        "    file_handler.setLevel(logging.DEBUG)\n",
        "\n",
        "    # Create console handler for console output\n",
        "    console_handler = logging.StreamHandler()\n",
        "    console_handler.setLevel(logging.INFO)\n",
        "\n",
        "    # Define the log format\n",
        "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')\n",
        "    file_handler.setFormatter(formatter)\n",
        "    console_handler.setFormatter(formatter)\n",
        "\n",
        "    # Add handlers to the logger\n",
        "    logger.addHandler(file_handler)\n",
        "    logger.addHandler(console_handler)\n",
        "\n",
        "    return logger\n",
        "\n",
        "# Initialize logger\n",
        "log_file_path = '/content/Sales_predictions_model.log'  # File path in Colab\n",
        "logger = setup_logger(log_file=log_file_path)"
      ],
      "metadata": {
        "id": "5q1D-ijYPY8R"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Log Steps in the Project\n",
        "logger.info(\"Starting Sales prediction project\")\n",
        "\n",
        "try:\n",
        "    logger.info(\"Loading data...\")\n",
        "    # Example: Replace with your actual data loading code\n",
        "    data = pd.DataFrame({'Date': pd.date_range(start='2024-12-12', periods=10, freq='W'),\n",
        "                         'Sales': [5530,4327,4486,4997,6026,4258,5052,4078,7025,6240]})\n",
        "    logger.info(\"Data loaded successfully.\")\n",
        "\n",
        "    logger.info(\"Preprocessing data...\")\n",
        "    # Example preprocessing\n",
        "    data['Date'] = pd.to_datetime(data['Date'])\n",
        "    logger.info(\"Data preprocessing completed.\")\n",
        "\n",
        "    logger.info(\"Splitting data...\")\n",
        "    # Split data example\n",
        "    train_data = data.iloc[:-2]\n",
        "    test_data = data.iloc[-2:]\n",
        "    logger.info(\"Data splitting completed.\")\n",
        "\n",
        "    logger.info(\"Training model...\")\n",
        "    # Example model training\n",
        "    model = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "    model.fit(train_data[['Sales']], train_data['Sales'])\n",
        "    logger.info(\"Model training completed.\")\n",
        "\n",
        "    logger.info(\"Evaluating model...\")\n",
        "    predictions = model.predict(test_data[['Sales']])\n",
        "    logger.info(f\"Predictions: {predictions}\")\n",
        "    logger.info(\"Evaluation completed.\")\n",
        "\n",
        "except Exception as e:\n",
        "    logger.error(f\"An error occurred: {e}\")\n",
        "\n",
        "# Step 3: Save and Access Logs\n",
        "model_file_path = '/content/Sales_predictions_model.pkl' # Create new file path for model\n",
        "joblib.dump(model, model_file_path)  # Save trained model to the new file\n",
        "logger.info(f\"Model saved to {model_file_path}\")\n",
        "\n",
        "#logger.info(f\"Logs saved to {log_file_path}\")"
      ],
      "metadata": {
        "id": "3Igf86b6kIoZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e89e7be3-8071-4978-f16b-9fbada031f90"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2025-01-02 11:38:51,936 - INFO - Starting Sales prediction project\n",
            "2025-01-02 11:38:51,936 - INFO - Starting Sales prediction project\n",
            "2025-01-02 11:38:51,936 - INFO - Starting Sales prediction project\n",
            "2025-01-02 11:38:51,936 - INFO - Starting Sales prediction project\n",
            "2025-01-02 11:38:51,936 - INFO - Starting Sales prediction project\n",
            "2025-01-02 11:38:51,936 - INFO - Starting Sales prediction project\n",
            "2025-01-02 11:38:51,936 - INFO - Starting Sales prediction project\n",
            "INFO:SalesPredictionLogger:Starting Sales prediction project\n",
            "2025-01-02 11:38:51,954 - INFO - Loading data...\n",
            "2025-01-02 11:38:51,954 - INFO - Loading data...\n",
            "2025-01-02 11:38:51,954 - INFO - Loading data...\n",
            "2025-01-02 11:38:51,954 - INFO - Loading data...\n",
            "2025-01-02 11:38:51,954 - INFO - Loading data...\n",
            "2025-01-02 11:38:51,954 - INFO - Loading data...\n",
            "2025-01-02 11:38:51,954 - INFO - Loading data...\n",
            "INFO:SalesPredictionLogger:Loading data...\n",
            "2025-01-02 11:38:51,967 - INFO - Data loaded successfully.\n",
            "2025-01-02 11:38:51,967 - INFO - Data loaded successfully.\n",
            "2025-01-02 11:38:51,967 - INFO - Data loaded successfully.\n",
            "2025-01-02 11:38:51,967 - INFO - Data loaded successfully.\n",
            "2025-01-02 11:38:51,967 - INFO - Data loaded successfully.\n",
            "2025-01-02 11:38:51,967 - INFO - Data loaded successfully.\n",
            "2025-01-02 11:38:51,967 - INFO - Data loaded successfully.\n",
            "INFO:SalesPredictionLogger:Data loaded successfully.\n",
            "2025-01-02 11:38:51,977 - INFO - Preprocessing data...\n",
            "2025-01-02 11:38:51,977 - INFO - Preprocessing data...\n",
            "2025-01-02 11:38:51,977 - INFO - Preprocessing data...\n",
            "2025-01-02 11:38:51,977 - INFO - Preprocessing data...\n",
            "2025-01-02 11:38:51,977 - INFO - Preprocessing data...\n",
            "2025-01-02 11:38:51,977 - INFO - Preprocessing data...\n",
            "2025-01-02 11:38:51,977 - INFO - Preprocessing data...\n",
            "INFO:SalesPredictionLogger:Preprocessing data...\n",
            "2025-01-02 11:38:51,987 - INFO - Data preprocessing completed.\n",
            "2025-01-02 11:38:51,987 - INFO - Data preprocessing completed.\n",
            "2025-01-02 11:38:51,987 - INFO - Data preprocessing completed.\n",
            "2025-01-02 11:38:51,987 - INFO - Data preprocessing completed.\n",
            "2025-01-02 11:38:51,987 - INFO - Data preprocessing completed.\n",
            "2025-01-02 11:38:51,987 - INFO - Data preprocessing completed.\n",
            "2025-01-02 11:38:51,987 - INFO - Data preprocessing completed.\n",
            "INFO:SalesPredictionLogger:Data preprocessing completed.\n",
            "2025-01-02 11:38:51,996 - INFO - Splitting data...\n",
            "2025-01-02 11:38:51,996 - INFO - Splitting data...\n",
            "2025-01-02 11:38:51,996 - INFO - Splitting data...\n",
            "2025-01-02 11:38:51,996 - INFO - Splitting data...\n",
            "2025-01-02 11:38:51,996 - INFO - Splitting data...\n",
            "2025-01-02 11:38:51,996 - INFO - Splitting data...\n",
            "2025-01-02 11:38:51,996 - INFO - Splitting data...\n",
            "INFO:SalesPredictionLogger:Splitting data...\n",
            "2025-01-02 11:38:52,006 - INFO - Data splitting completed.\n",
            "2025-01-02 11:38:52,006 - INFO - Data splitting completed.\n",
            "2025-01-02 11:38:52,006 - INFO - Data splitting completed.\n",
            "2025-01-02 11:38:52,006 - INFO - Data splitting completed.\n",
            "2025-01-02 11:38:52,006 - INFO - Data splitting completed.\n",
            "2025-01-02 11:38:52,006 - INFO - Data splitting completed.\n",
            "2025-01-02 11:38:52,006 - INFO - Data splitting completed.\n",
            "INFO:SalesPredictionLogger:Data splitting completed.\n",
            "2025-01-02 11:38:52,015 - INFO - Training model...\n",
            "2025-01-02 11:38:52,015 - INFO - Training model...\n",
            "2025-01-02 11:38:52,015 - INFO - Training model...\n",
            "2025-01-02 11:38:52,015 - INFO - Training model...\n",
            "2025-01-02 11:38:52,015 - INFO - Training model...\n",
            "2025-01-02 11:38:52,015 - INFO - Training model...\n",
            "2025-01-02 11:38:52,015 - INFO - Training model...\n",
            "INFO:SalesPredictionLogger:Training model...\n",
            "2025-01-02 11:38:52,319 - INFO - Model training completed.\n",
            "2025-01-02 11:38:52,319 - INFO - Model training completed.\n",
            "2025-01-02 11:38:52,319 - INFO - Model training completed.\n",
            "2025-01-02 11:38:52,319 - INFO - Model training completed.\n",
            "2025-01-02 11:38:52,319 - INFO - Model training completed.\n",
            "2025-01-02 11:38:52,319 - INFO - Model training completed.\n",
            "2025-01-02 11:38:52,319 - INFO - Model training completed.\n",
            "INFO:SalesPredictionLogger:Model training completed.\n",
            "2025-01-02 11:38:52,336 - INFO - Evaluating model...\n",
            "2025-01-02 11:38:52,336 - INFO - Evaluating model...\n",
            "2025-01-02 11:38:52,336 - INFO - Evaluating model...\n",
            "2025-01-02 11:38:52,336 - INFO - Evaluating model...\n",
            "2025-01-02 11:38:52,336 - INFO - Evaluating model...\n",
            "2025-01-02 11:38:52,336 - INFO - Evaluating model...\n",
            "2025-01-02 11:38:52,336 - INFO - Evaluating model...\n",
            "INFO:SalesPredictionLogger:Evaluating model...\n",
            "2025-01-02 11:38:52,386 - INFO - Predictions: [5816.55 5816.55]\n",
            "2025-01-02 11:38:52,386 - INFO - Predictions: [5816.55 5816.55]\n",
            "2025-01-02 11:38:52,386 - INFO - Predictions: [5816.55 5816.55]\n",
            "2025-01-02 11:38:52,386 - INFO - Predictions: [5816.55 5816.55]\n",
            "2025-01-02 11:38:52,386 - INFO - Predictions: [5816.55 5816.55]\n",
            "2025-01-02 11:38:52,386 - INFO - Predictions: [5816.55 5816.55]\n",
            "2025-01-02 11:38:52,386 - INFO - Predictions: [5816.55 5816.55]\n",
            "INFO:SalesPredictionLogger:Predictions: [5816.55 5816.55]\n",
            "2025-01-02 11:38:52,403 - INFO - Evaluation completed.\n",
            "2025-01-02 11:38:52,403 - INFO - Evaluation completed.\n",
            "2025-01-02 11:38:52,403 - INFO - Evaluation completed.\n",
            "2025-01-02 11:38:52,403 - INFO - Evaluation completed.\n",
            "2025-01-02 11:38:52,403 - INFO - Evaluation completed.\n",
            "2025-01-02 11:38:52,403 - INFO - Evaluation completed.\n",
            "2025-01-02 11:38:52,403 - INFO - Evaluation completed.\n",
            "INFO:SalesPredictionLogger:Evaluation completed.\n",
            "2025-01-02 11:38:52,495 - INFO - Model saved to /content/Sales_predictions_model.pkl\n",
            "2025-01-02 11:38:52,495 - INFO - Model saved to /content/Sales_predictions_model.pkl\n",
            "2025-01-02 11:38:52,495 - INFO - Model saved to /content/Sales_predictions_model.pkl\n",
            "2025-01-02 11:38:52,495 - INFO - Model saved to /content/Sales_predictions_model.pkl\n",
            "2025-01-02 11:38:52,495 - INFO - Model saved to /content/Sales_predictions_model.pkl\n",
            "2025-01-02 11:38:52,495 - INFO - Model saved to /content/Sales_predictions_model.pkl\n",
            "2025-01-02 11:38:52,495 - INFO - Model saved to /content/Sales_predictions_model.pkl\n",
            "INFO:SalesPredictionLogger:Model saved to /content/Sales_predictions_model.pkl\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Deployment"
      ],
      "metadata": {
        "id": "MEz_kadz1N4Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5VEu_0xBtZH3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install flask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHN_Brk8tZSB",
        "outputId": "7d1403ae-11a1-4567-8864-32832becbcda"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: flask in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.3)\n",
            "Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.10/dist-packages (from flask) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.10/dist-packages (from flask) (2.2.0)\n",
            "Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from flask) (8.1.7)\n",
            "Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.10/dist-packages (from flask) (1.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import joblib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Flask app\n",
        "app = Flask(__name__)\n",
        "\n",
        "# Load the saved model027\n",
        "model_path = '/content/Sales_predictions_model.pkl'  # Update this path\n",
        "\n",
        "model = joblib.load(model_path)\n",
        "\n",
        "@app.route('/')\n",
        "def home():\n",
        "    return \"Sales Prediction Model API is running!\"\n",
        "\n",
        "# Prediction endpoint\n",
        "@app.route('/predict', methods=['POST'])\n",
        "def predict():\n",
        "    try:\n",
        "        # Get data from the POST request (expecting JSON)\n",
        "        data = request.get_json(force=True)\n",
        "\n",
        "        # Assuming the input features are in a list called 'features'\n",
        "        input_data = pd.DataFrame([data]) # Create DataFrame from input\n",
        "\n",
        "        # Preprocess the input data (extract date features)\n",
        "        input_data['Date'] = pd.to_datetime(input_data['Date'])\n",
        "        input_data['Year'] = input_data['Date'].dt.year\n",
        "        input_data['Month'] = input_data['Date'].dt.month\n",
        "        input_data['WeekOfYear'] =input_data['Date'].dt.isocalendar().week\n",
        "        input_data['Day'] = input_data['Date'].dt.day\n",
        "        # Add other date-related features if needed\n",
        "\n",
        "        # Drop the original 'Date' column\n",
        "        input_data = input_data.drop(columns=['Date'])\n",
        "\n",
        "        # Get predictions from the model\n",
        "        prediction = model.predict(input_data)\n",
        "\n",
        "        # Return the prediction as a JSON response\n",
        "        return jsonify({'prediction': prediction.tolist()})\n",
        "\n",
        "    except Exception as e:\n",
        "        return jsonify({'error': str(e)}), 400\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True, port=5000)  # Run on port 5000"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZetOUSlviyh",
        "outputId": "d65fa576-9198-4894-d1d1-b5772db8f43f"
      },
      "execution_count": 34,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " * Serving Flask app '__main__'\n",
            " * Debug mode: on\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
            " * Running on http://127.0.0.1:5000\n",
            "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
            "INFO:werkzeug: * Restarting with stat\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Running Flask in Colab:"
      ],
      "metadata": {
        "id": "8d-cHaO71llu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok"
      ],
      "metadata": {
        "id": "RdvDfRBM04ev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Use ngrok to Expose the Flask App:"
      ],
      "metadata": {
        "id": "EEYsGFvz1zJ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "\n",
        "# Set up a tunnel to the Flask app (run it on port 5000)\n",
        "sales = ngrok.connect(5000 )\n",
        "print(f\"Flask app is running at {public_url}\")"
      ],
      "metadata": {
        "id": "job9MLo008XR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app.run(port=5000)  # start flask app"
      ],
      "metadata": {
        "id": "Vik_Bpzs1Bdn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}